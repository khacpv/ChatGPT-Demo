python -m llama_cpp.server --model "D:\Development\OpenAI\Faraday-Models\llama2.20b.mlewd-remm.gguf_v2.q4_k_m.gguf" --chat_format chatml --n_gpu_layers 1